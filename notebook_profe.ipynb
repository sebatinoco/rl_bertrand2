{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: dqn_experiment \t Episode: 1/1 \t Episode completion: 100.00 % \t Delta: 0.69"
     ]
    }
   ],
   "source": [
    "from agents.dqn import DQNAgent\n",
    "from agents.sac import SACAgent\n",
    "from envs.LinearBertrandInflation import LinearBertrandEnv\n",
    "from envs.BertrandInflation import BertrandEnv\n",
    "from replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "N = 3\n",
    "k = 2\n",
    "rho = 2e-4\n",
    "#rho = 0.0\n",
    "timesteps = 150_000\n",
    "buffer_size = 200_000\n",
    "sample_size = 256\n",
    "update_steps = 1\n",
    "deviate_start = 0.8\n",
    "deviate_end = 0.9\n",
    "random_state = 3381\n",
    "\n",
    "np.random.seed(random_state)\n",
    "\n",
    "variation = 'base'\n",
    "\n",
    "dim_states = (N * k) + k + 1\n",
    "dim_actions = 15\n",
    "#dim_actions = 1\n",
    "\n",
    "#env = LinearBertrandEnv(N, k, rho, timesteps, dim_actions=dim_actions)\n",
    "env = BertrandEnv(N, k, rho, timesteps, dim_actions=dim_actions, max_var=2.0, mu = 0.25,\n",
    "                  random_state = 3380, use_inflation_data=True, normalize=False)\n",
    "buffer = ReplayBuffer(dim_states, N, k, buffer_size, sample_size)\n",
    "\n",
    "agents = [DQNAgent(N, k, dim_actions, beta = 5e-5, lr = 1e-1, agent_idx = agent_idx) for agent_idx in range(N)]\n",
    "#agents = [SACAgent(dim_states, dim_actions) for _ in range(N)]\n",
    "\n",
    "exp_name = 'dqn_experiment'\n",
    "episodes = 1\n",
    "\n",
    "prices_history = np.zeros((episodes, timesteps, N))\n",
    "actions_history = np.zeros((episodes, timesteps, N))\n",
    "costs_history = np.zeros((episodes, timesteps))\n",
    "monopoly_history = np.zeros((episodes, timesteps))\n",
    "nash_history = np.zeros((episodes, timesteps))\n",
    "rewards_history = np.zeros((episodes, timesteps, N))\n",
    "delta_history = np.zeros((episodes, timesteps))\n",
    "quantities_history = np.zeros((episodes, timesteps, N))\n",
    "pi_N_history = np.zeros((episodes, timesteps))\n",
    "pi_M_history = np.zeros((episodes, timesteps))\n",
    "A_history = np.zeros((episodes, timesteps))\n",
    "\n",
    "ob_t = env.reset()\n",
    "for episode in range(episodes):\n",
    "    for t in range(timesteps):\n",
    "        \n",
    "        actions = [agent.select_action(ob_t) for agent in agents]\n",
    "        \n",
    "        if variation == 'deviate':\n",
    "            if (t/timesteps > deviate_start) and (t/timesteps <= deviate_end):\n",
    "                env.trigger_deviation = True\n",
    "            \n",
    "            elif t/timesteps > deviate_end:\n",
    "                env.trigger_deviation = False\n",
    "        \n",
    "        elif variation == 'altruist':\n",
    "            env.altruist = True\n",
    "        \n",
    "        ob_t1, rewards, done, info = env.step(actions)\n",
    "        \n",
    "        experience = (ob_t, actions, rewards, ob_t1, done)\n",
    "        \n",
    "        buffer.store_transition(*experience)\n",
    "        \n",
    "        if (t % update_steps == 0) & (t >= buffer.sample_size):\n",
    "            for agent_idx in range(N):\n",
    "                agent = agents[agent_idx]\n",
    "                sample = buffer.sample(agent_idx)\n",
    "                agent.update(*sample)\n",
    "                \n",
    "        sys.stdout.write(f\"\\rExperiment: {exp_name} \\t Episode: {episode + 1}/{episodes} \\t Episode completion: {100 * t/timesteps:.2f} % \\t Delta: {info:.2f}\")\n",
    "                \n",
    "        ob_t = ob_t1\n",
    "        \n",
    "    # store episode metrics\n",
    "    prices_history[episode] = np.array(env.prices_history)[-timesteps:]\n",
    "    actions_history[episode] = np.array(env.action_history)[-timesteps:]\n",
    "    costs_history[episode] = np.array(env.costs_history)[-timesteps:]\n",
    "    monopoly_history[episode] = np.array(env.monopoly_history)[-timesteps:]\n",
    "    nash_history[episode] = np.array(env.nash_history)[-timesteps:]\n",
    "    rewards_history[episode] = np.array(env.rewards_history)[-timesteps:]\n",
    "    delta_history[episode] = np.array(env.metric_history)[-timesteps:]\n",
    "    quantities_history[episode] = np.array(env.quantities_history)[-timesteps:]\n",
    "    pi_N_history[episode] = np.array(env.pi_N_history)[-timesteps:]\n",
    "    pi_M_history[episode] = np.array(env.pi_M_history)[-timesteps:]\n",
    "    A_history[episode] = np.array(env.A_history)[-timesteps:]\n",
    "\n",
    "prices_history = np.mean(prices_history, axis = 0)\n",
    "actions_history = np.mean(actions_history, axis = 0)\n",
    "costs_history = np.mean(costs_history, axis = 0)\n",
    "monopoly_history = np.mean(monopoly_history, axis = 0)\n",
    "nash_history = np.mean(nash_history, axis = 0)\n",
    "rewards_history = np.mean(rewards_history, axis = 0)\n",
    "delta_history = np.mean(delta_history, axis = 0)\n",
    "quantities_history = np.mean(quantities_history, axis = 0)\n",
    "pi_N_history = np.mean(pi_N_history, axis = 0)\n",
    "pi_M_history = np.mean(pi_M_history, axis = 0)\n",
    "A_history = np.mean(A_history, axis = 0) # equal disposition to pay\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('models/agent_3381.pkl', 'wb') as file:\n",
    "    pickle.dump(agents[0], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = ob_t\n",
    "\n",
    "prices_costs = state[:, 1:-k].reshape(-1, k, N) # take just prices - costs\n",
    "self_price = prices_costs[:, :, agent_idx] # gather own series\n",
    "other_prices = np.delete(prices_costs, agent_idx, axis = 2).reshape(-1, k * (N - 1)) # gather rest of series\n",
    "cost_t = np.expand_dims(state[:, 0], 1)\n",
    "past_costs = state[:, -k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "agent = 2\n",
    "\n",
    "#env = LinearBertrandEnv(N, k, rho, timesteps, dim_actions=dim_actions)\n",
    "env = BertrandEnv(N, k, rho, timesteps, dim_actions=dim_actions, max_var=2.0, mu = 0.25,\n",
    "                  random_state = random_state, use_inflation_data=True, normalize=False)\n",
    "buffer = ReplayBuffer(dim_states, N, buffer_size, sample_size)\n",
    "\n",
    "cost_t = np.expand_dims(state[:, 0], 1)\n",
    "past_costs = state[:, -k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, states_t1, done = buffer.sample(1)\n",
    "\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_costs = state[:, 1:-k].reshape(batch_size, k, N) # take just prices - costs\n",
    "self_price = prices_costs[:, :, agent] # gather own series\n",
    "other_prices = np.delete(prices_costs, agent, axis = 2).reshape(batch_size, k * (N - 1)) # gather rest of series\n",
    "cost_t = np.expand_dims(state[:, 0], 1)\n",
    "past_costs = state[:, -k:]\n",
    "\n",
    "np.array((prices_costs,self_price,other_prices,cost_t,past_costs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, actions, rewards, state_t1, done = buffer.sample(1)\n",
    "\n",
    "def split_state(state, N, k, idx):\n",
    "    \n",
    "    prices_costs = state[:, 1:-k].reshape(-1, k, N) # take just prices - costs\n",
    "    self_price = prices_costs[:, :, idx] # gather own series\n",
    "    other_prices = np.delete(prices_costs, idx, axis = 2).reshape(-1, k * (N - 1)) # gather rest of series\n",
    "    cost_t = np.expand_dims(state[:, 0], 1)\n",
    "    past_costs = state[:, -k:]\n",
    "    \n",
    "    return (self_price, other_prices, cost_t, past_costs)\n",
    "\n",
    "split_state(state, N, k, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, action, reward, state_t1, done = buffer.sample(1)\n",
    "\n",
    "exp_name = 'dqn_experiment'\n",
    "episodes = 1\n",
    "\n",
    "prices_costs = state[:, 1:-k].reshape(batch_size, k, N) # take just prices - costs\n",
    "self_price = prices_costs[:, :, agent] # gather own series\n",
    "other_prices = np.delete(prices_costs, agent, axis = 2).reshape(batch_size, k * (N - 1)) # gather rest of series\n",
    "cost_t = np.expand_dims(state[:, 0], 1)\n",
    "past_costs = state[:, -k:]\n",
    "\n",
    "prices_history = np.mean(prices_history, axis = 0)\n",
    "actions_history = np.mean(actions_history, axis = 0)\n",
    "costs_history = np.mean(costs_history, axis = 0)\n",
    "monopoly_history = np.mean(monopoly_history, axis = 0)\n",
    "nash_history = np.mean(nash_history, axis = 0)\n",
    "rewards_history = np.mean(rewards_history, axis = 0)\n",
    "delta_history = np.mean(delta_history, axis = 0)\n",
    "quantities_history = np.mean(quantities_history, axis = 0)\n",
    "pi_N_history = np.mean(pi_N_history, axis = 0)\n",
    "pi_M_history = np.mean(pi_M_history, axis = 0)\n",
    "A_history = np.mean(A_history, axis = 0) # equal disposition to pay\n",
    "\n",
    "# dim_states = (N * k) + k + 1\n",
    "\n",
    "print(f'self_price: {self_price.shape}') # (batch_size, k)\n",
    "print(f'other_prices: {other_prices.shape}') # (batch_size, (N - 1) * k)\n",
    "print(f'cost_t: {cost_t.shape}') # (batch_size, 1)\n",
    "print(f'past_costs: {past_costs.shape}') # (batch_size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "self_price_embedding = nn.Linear(k, 1) \n",
    "other_prices_embedding = nn.Linear((N-1) * k, 1)\n",
    "cost_t_embedding = nn.Linear(1, 1)\n",
    "past_costs_embedding = nn.Linear(k, 1)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, N, k, output_size, hidden_size = 256, num_layers = 2, dropout = 0.1, random_state = 3380):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        torch.manual_seed(random_state)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed(random_state)\n",
    "        torch.cuda.manual_seed_all(random_state)\n",
    "        \n",
    "        self.self_price_embedding = nn.Linear(k, 1) \n",
    "        self.other_prices_embedding = nn.Linear((N-1) * k, 1)\n",
    "        self.cost_t_embedding = nn.Linear(1, 1)\n",
    "        self.past_costs_embedding = nn.Linear(k, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, self_price, other_prices, cost_t, past_costs):\n",
    "        \n",
    "        self_price = self.self_price_embedding(self_price)\n",
    "        other_prices = self.other_prices_embedding(other_prices)\n",
    "        cost_t = self.cost_t_embedding(cost_t)\n",
    "        past_costs = self.past_costs_embedding(past_costs)\n",
    "        \n",
    "        state = torch.cat([self_price, other_prices, cost_t, past_costs], axis = 1)\n",
    "        print(state.shape)\n",
    "        \n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        return self.fc3(x)\n",
    "    \n",
    "model = DQN(N, k, 15)\n",
    "\n",
    "model(self_price, other_prices, cost_t, past_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESPERAR A ENTRENAR AGENTES 3381 Y 3382\n",
    "# CARGAR AGENTES EN AMBIENTE TRAIN TEST CON SEMILLA 500\n",
    "# GRAFICAR\n",
    "\n",
    "# LUEGO EXPORTAR RESULTADOS A LATEX\n",
    "# GENERAR FIGURAS Y REALIZAR PRESENTACION --> DEBERIA AVANZAR EN ESTOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_metrics import get_rolling, get_rolling_std\n",
    "import pandas as pd\n",
    "\n",
    "## EXPORT\n",
    "results = pd.DataFrame({'costs': costs_history,\n",
    "                        'pi_N': pi_N_history,\n",
    "                        'pi_M': pi_M_history,\n",
    "                        'delta': delta_history,\n",
    "                        'p_nash': nash_history,\n",
    "                        'p_monopoly': monopoly_history,\n",
    "                        'A': A_history,\n",
    "                        })\n",
    "\n",
    "for agent in range(env.N):\n",
    "    results[f'actions_{agent}'] = actions_history[:, agent]\n",
    "    results[f'prices_{agent}'] = prices_history[:, agent]\n",
    "    results[f'quantities_{agent}'] = quantities_history[:, agent]\n",
    "    results[f'rewards_{agent}'] = rewards_history[:, agent]\n",
    "    \n",
    "results.to_csv(f'test2.csv', index = False, sep = ';', encoding = 'utf-8-sig')\n",
    "\n",
    "## READ AND PREPARE\n",
    "window_size = 1000\n",
    "df_avg = pd.DataFrame()\n",
    "df_std = pd.DataFrame()\n",
    "\n",
    "df_plot = pd.read_csv('test2.csv', sep = ';', encoding = 'utf-8-sig')\n",
    "\n",
    "actions_cols = [col for col in df_plot.columns if 'actions' in col]\n",
    "price_cols = [col for col in df_plot.columns if 'prices' in col]\n",
    "rewards_cols = [col for col in df_plot.columns if 'rewards' in col]\n",
    "quantities_cols = [col for col in df_plot.columns if 'quantities' in col]\n",
    "\n",
    "n_agents = len(actions_cols)\n",
    "\n",
    "df_plot['avg_actions'] = df_plot[actions_cols].mean(axis = 1)\n",
    "df_plot['avg_prices'] = df_plot[price_cols].mean(axis = 1)\n",
    "df_plot['avg_rewards'] = df_plot[rewards_cols].mean(axis = 1)\n",
    "df_plot['avg_quantities'] = df_plot[quantities_cols].mean(axis = 1)\n",
    "avg_cols = [col for col in df_plot.columns if 'avg' in col]\n",
    "\n",
    "window_cols = price_cols + rewards_cols + quantities_cols + avg_cols + ['delta']\n",
    "for col in window_cols:\n",
    "    df_avg[col] = get_rolling(df_plot[col], window_size = window_size)\n",
    "    df_std[col] = get_rolling_std(df_plot[col], window_size = window_size)\n",
    "\n",
    "series_size = df_avg.shape[0]\n",
    "\n",
    "df_plot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (12, 4))\n",
    "for agent in range(n_agents):\n",
    "    serie = f'prices_{agent}'\n",
    "    #plt.plot(price_serie, label = f'Agent {agent}')\n",
    "    plt.errorbar(range(series_size), df_avg[serie], df_std[serie], errorevery=int(0.01 * series_size), label = f'Agent {agent}')\n",
    "plt.plot(df_plot['p_monopoly'], color = 'red', label = 'Monopoly price')\n",
    "plt.plot(df_plot['p_nash'], color = 'green', label = 'Nash price')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Prices')\n",
    "plt.title('Experiments Results Sample')\n",
    "plt.legend()\n",
    "plt.savefig('prices.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "std_avg = get_rolling(agents[0].mean_history, window_size)\n",
    "std_std = get_rolling_std(agents[0].mean_history, window_size)\n",
    "\n",
    "std_size = len(std_std)\n",
    "\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.errorbar(range(std_size), std_avg, std_std, errorevery=int(0.01 * std_size))\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Standard Deviation (std)')\n",
    "plt.title('Standard Deviation of Agent 0')\n",
    "#plt.savefig('desviacion_estandar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "std_avg = get_rolling(agents[0].std_history, window_size)\n",
    "std_std = get_rolling_std(agents[0].std_history, window_size)\n",
    "\n",
    "std_size = len(std_std)\n",
    "\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.errorbar(range(std_size), std_avg, std_std, errorevery=int(0.01 * std_size))\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Standard Deviation (std)')\n",
    "plt.title('Standard Deviation of Agent 0')\n",
    "#plt.savefig('desviacion_estandar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "size = len(df_avg[serie])\n",
    "plt.figure(figsize = (12, 4))\n",
    "#plt.plot(df_plot['avg_prices'], label = 'Average prices')\n",
    "plt.errorbar(range(series_size), df_avg['avg_prices'], df_std['avg_prices'], errorevery=int(0.01 * series_size), label = f'Average prices')\n",
    "plt.plot(df_plot['p_monopoly'], color = 'red', label = 'Monopoly price')\n",
    "plt.plot(df_plot['p_nash'], color = 'green', label = 'Nash price')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Prices')\n",
    "plt.legend()\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "#plt.plot(df_plot['avg_rewards'], label = 'Average profits')\n",
    "plt.errorbar(range(series_size), df_avg['avg_rewards'], df_std['avg_rewards'], errorevery=int(0.01 * series_size), label = f'Average profits')\n",
    "plt.plot(df_plot['pi_N'], label = 'Nash profits', color = 'green')\n",
    "plt.plot(df_plot['pi_M'], label = 'Monopoly profits', color = 'red')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Profits')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "#plt.plot(df_plot['delta'], label = 'Average profits')\n",
    "plt.errorbar(range(series_size), df_avg['delta'], df_std['delta'], errorevery=int(0.01 * series_size), label = f'Average profits')\n",
    "plt.axhline(1, color = 'red', label = 'Nash profits')\n",
    "plt.axhline(0, color = 'green', label = 'Monoply profits')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Delta')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "df  = pd.read_csv('test2.csv', sep = ';')\n",
    "df = df.iloc[8000:8000 + sample_size]\n",
    "df['rewards_0'] = df['rewards_0'].replace(0, np.nan)\n",
    "df['rewards_1'] = df['rewards_1'].replace(0, np.nan)\n",
    "\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Crea un histograma para la columna\n",
    "plt.hist(df['prices_0'], bins=30, color='blue', alpha=0.7)\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de Precios')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Crea un histograma para la columna\n",
    "plt.hist(df['rewards_0'], bins=30, color='blue', alpha=0.7)\n",
    "plt.xlabel('Valores')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de Recompensas')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_df = df.rolling(10).mean().dropna()\n",
    "rolling_df = rolling_df[['prices_0', 'p_nash', 'p_monopoly', 'rewards_0', 'pi_N', 'pi_M']]\n",
    "rolling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "A = 2\n",
    "c = 1\n",
    "epsilon = 1\n",
    "\n",
    "prices = np.arange(1, 2.01, 0.01)\n",
    "\n",
    "pi_list = []\n",
    "for p in prices:\n",
    "    q = A - epsilon * p\n",
    "    pi = (p - c) * q\n",
    "    \n",
    "    pi_list.append(pi)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar valores mayores o iguales a 0 en el eje Y\n",
    "filtered_pi_list = [pi if pi >= 0 else 0 for pi in pi_list]\n",
    "\n",
    "plt.figure(figsize = (8, 4))\n",
    "plt.plot(prices, filtered_pi_list)\n",
    "plt.xlabel(\"$p_{i,t}$\")\n",
    "plt.ylabel(\"$R_{i,t}$\")\n",
    "#plt.title(\"Revenue maximization curve\")\n",
    "#plt.axvline(1.5, linestyle = '--', color = 'red')\n",
    "#plt.axvline(2, linestyle = '--', color = 'green')\n",
    "#plt.ylim(0, 0.252)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.xticks([])  # Oculta las etiquetas del eje X\n",
    "plt.yticks([])  # Oculta las etiquetas del eje Y\n",
    "plt.savefig('demmand_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "serie_1 = np.random.randint(1, 5, 10)\n",
    "serie_2 = np.random.randint(1, 5, 10)\n",
    "serie_3 = np.random.randint(1, 5, 10)\n",
    "\n",
    "plt.figure(figsize = (8, 4))\n",
    "plt.plot(serie_1, color = 'C0', label = 'serie_1')\n",
    "plt.plot(serie_2, color = 'C1', label = 'serie_2')\n",
    "plt.plot(serie_3, color = 'C4', label = 'serie_3')\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "env = 'linear'\n",
    "parameters = ['N', 'gamma', 'rho', 'lr', 'k']\n",
    "\n",
    "metrics = os.listdir('metrics')\n",
    "metrics = [metric for metric in metrics if (env in metric) and ('altruist' not in metric) and ('deviate' not in metric)]\n",
    "metrics += ['linear_sac_base_1_altruist.csv']\n",
    "\n",
    "delta_base = pd.read_csv('metrics/linear_sac_base_1.csv', sep = ';')['delta']\n",
    "\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    \n",
    "    df_metric = pd.read_csv(f'metrics/{metric}', sep = ';')\n",
    "    delta_metric = df_metric['delta']\n",
    "    avg_delta = np.round(np.mean(delta_metric), 2)\n",
    "    \n",
    "    t_statistic, p_value = stats.ttest_ind(delta_base, delta_metric)\n",
    "    p_value = np.round(p_value, 2)\n",
    "    \n",
    "    results[metric] = [avg_delta, p_value]\n",
    "    \n",
    "df_results = pd.DataFrame(results.values(), index = results.keys(), columns=['Delta', 'p_value'])\n",
    "df_results = df_results.sort_values(by = 'Delta', ascending = False)\n",
    "\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "metrics = os.listdir(f'metrics/')\n",
    "\n",
    "parameters = ['N', 'gamma', 'rho', 'lr', 'k']\n",
    "envs = list(set([metric.split('_')[0] for metric in metrics if '.csv' in metric]))\n",
    "models = list(set([metric.split('_')[1] for metric in metrics if '.csv' in metric]))\n",
    "for env in envs:\n",
    "    env_metrics = [metric for metric in metrics if env in metric]\n",
    "    for model in models:\n",
    "        model_metrics = [metric for metric in env_metrics if model in metric]\n",
    "        base_metric = f'{env}_{model}_base_1.csv'\n",
    "        for parameter in parameters:\n",
    "            final_metrics = sorted([metric for metric in model_metrics if parameter in metric])\n",
    "            \n",
    "            if base_metric in metrics:\n",
    "                final_metrics = sorted(final_metrics + [f'{env}_{model}_base_1.csv'])\n",
    "\n",
    "            print(f'final_metrics: {final_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
